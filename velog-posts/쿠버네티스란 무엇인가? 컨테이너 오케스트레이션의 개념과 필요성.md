<p><img alt="" src="https://velog.velcdn.com/images/ysheep0906/post/199a7219-ec45-42e8-b29d-ae6c1433df65/image.png" /></p>
<h2 id="컨테이너-오케스트레이션의-필요성">컨테이너 오케스트레이션의 필요성</h2>
<p>과거에는 서버 한 대에 애플리케이션을 직접 설치하고 한 번에 운영하는 모놀리식 구조를 사용하였다. 하지만 서비스가 커지고 <strong>마이크로서비스(MSA)</strong>가 도입되면서 <strong>수 백 ~ 수 천 개의 컨테이너</strong>를 관리해야하는 시대가 와버렸다!</p>
<p>그렇다면 기본 도커 환경만을 가지고 관리를 해야한다면 문제가 시작이 된다.</p>
<ul>
<li>트래픽이 몰렸을 때 컨테이너를 수동으로 띄워야 함(스케일링 문제)</li>
<li>업데이트할 때 중단 없이 배포하기 어려움</li>
<li>갑자기 장애가 나면 컨테이너를 수동으로 재시작해야 함</li>
</ul>
<p>이러한 문제들을 자동으로 해결해주는 시스템이 바로 <strong>쿠버네티스(Kubernetes)</strong>다!</p>
<h2 id="docker-vs-kubernetes">Docker vs Kubernetes</h2>
<p>도커와 쿠버네티스를 비교해보자! 사실 비교하는 의미가 없고 이 두 개는 협력 관계라고 볼 수있다. 
<img alt="" src="https://velog.velcdn.com/images/ysheep0906/post/595ae26f-239e-4e95-9f72-926cc66155be/image.png" /></p>
<h3 id="docker">Docker</h3>
<p>Docker는 애플리케이션을 <strong>독립된 환경</strong>에서 실행할 수 있도록 만들어주는 기술이다.
하나의 호스트 OS 위에서, 필요한 라이브러리와 프레임워크를 함께 패키징해 실행한다.</p>
<p>구조적으로 보면 다음과 같다:</p>
<ul>
<li><p>App / Framework / Libraries → <em>애플리케이션 코드와 실행환경</em></p>
</li>
<li><p>Containers → <em>독립된 실행 단위 (하나의 서비스 또는 프로세스)</em></p>
</li>
<li><p>Docker Engine → <em>컨테이너를 생성하고 관리하는 런타임</em></p>
</li>
<li><p>Operating System &amp; Hardware → <em>실제 물리/가상 머신</em></p>
</li>
</ul>
<blockquote>
<p>즉, Docker는 한 대의 서버(Host OS)에서 여러 개의 컨테이너를 실행하는 기술이다.</p>
</blockquote>
<h3 id="kubernetes">Kubernetes</h3>
<p>여러 개의 <strong>서버(Host)</strong>를 하나의 <strong>클러스터(Cluster)</strong>로 묶어, 그 위에서 컨테이너를 자동으로 배포, 확장, 복구하는 역할을 한다.</p>
<p>Kubernetes는 여러 Host 위에 각각 Docker(또는 containerd)가 설치된 환경을 관리한다.</p>
<p>각 Host에는 <strong>Kubernetes Agent (kubelet)</strong>이 동작하며, 중앙 제어(Control Plane)와 통신한다.</p>
<p>개발자는 직접 서버에 접속하지 않고, 오직 API Server에 명령을 보내면 된다.</p>
<blockquote>
<p>즉, “Docker가 단일 머신의 컨테이너를 관리한다면, Kubernetes는 여러 머신의 컨테이너를 한꺼번에 관리한다.”</p>
</blockquote>
<h2 id="쿠버네티스의-핵심-구성요소">쿠버네티스의 핵심 구성요소</h2>
<p><img alt="" src="https://velog.velcdn.com/images/ysheep0906/post/73b2ef1a-b4f9-4967-8d24-6eacc9ac62f0/image.png" /></p>
<h3 id="1-control-plane-제어-영역">1. Control Plane (제어 영역)</h3>
<p>Control Plane은 쿠버네티스의 &quot;두뇌”에 해당한다고 생각하면 된다. 사용자가 kubectl로 명령을 내리면, <strong>전체 클러스터의 상태를 관리하고 스케줄링을 수행</strong>한다.</p>
<ul>
<li>API Server: 클러스터의 <strong><em>모든 명령이 통과</em></strong>하는 진입점. kubectl이 API Server를 통해 명령을 전달한다.</li>
<li>etcd: 클러스터의 모든 상태를 <strong>저장</strong>하는 고가용성 Key-Value 데이터베이스. <em>(예: 어떤 Pod가 어디서 실행 중인지 등)</em></li>
<li>Controller Manager: 클러스터의 상태를 <strong>지속적으로 감시</strong>하고, “원하는 상태(desired state)”로 유지되도록 자동 조정한다.</li>
<li>Scheduler: 새로 생성된 Pod를 <strong>어떤 Node에 배치</strong>할지 결정한다. 리소스 사용량, affinity 등을 고려하여 최적의 위치를 선택한다.</li>
</ul>
<h3 id="2-node-실행-영역">2. Node (실행 영역)</h3>
<p>Node는 실제로 컨테이너가 실행되는 물리적 또는 가상 머신이다. Control Plane이 “두뇌”라면 Node는 “손발” 역할을 한다.</p>
<ul>
<li>kubelet: Node의 핵심 에이전트. Control Plane에서 전달된 <strong>명령을 수행</strong>하고, Pod 상태를 주기적으로 보고한다.</li>
<li>kube-proxy: 네트워크 프록시로서, Pod 간 통신과 Service 트래픽 라우팅을 관리한다.</li>
<li>Container Runtime: 실제 컨테이너를 실행하는 엔진 (예: containerd, CRI-O 등). Docker도 초기에는 여기서 사용되었다.</li>
</ul>
<h2 id="쿠버네티스의-장점">쿠버네티스의 장점</h2>
<h3 id="자동화된-배포와-복구">자동화된 배포와 복구</h3>
<p>Pod가 비정상적으로 종료되면 kubelet이 <strong>자동으로 재시작</strong>한다. Node 장애 시, 해당 Node의 Pod는 다른 Node로 자동 재배치된다. Deployment의 롤링 업데이트 기능을 통해 서비스 중단 없이 새 버전 배포가 가능하다.</p>
<h3 id="수평-확장-horizontal-scaling">수평 확장 (Horizontal Scaling)</h3>
<p>트래픽이 늘어나면 <strong>HorizontalPodAutoscaler(HPA)</strong>가 CPU·메모리 사용량을 모니터링하고 자동으로 Pod를 늘린다. 트래픽이 줄어들면 다시 줄여 리소스를 절약한다.
→ 이는 클라우드 비용 절감과 효율적 자원 사용에 큰 장점이 있다.</p>
<h3 id="무중단-롤링-업데이트">무중단 롤링 업데이트</h3>
<p>새 버전의 애플리케이션을 배포할 때, 기존 Pod를 한꺼번에 내리지 않는다. 대신 새 Pod를 하나씩 올리면서 기존 Pod를 하나씩 내리는 방식으로 서비스 중단을 최소화한다.</p>
<h3 id="클라우드-네이티브-환경과의-연계">클라우드 네이티브 환경과의 연계</h3>
<p>Kubernetes는 AWS EKS, GCP GKE, Azure AKS 같은 클라우드 서비스와 완벽히 호환된다. CI/CD, 모니터링, 오토스케일링 같은 클라우드 네이티브 도구들과 쉽게 연동되어 현대적인 DevOps 워크플로우의 중심 역할을 한다.</p>
<blockquote>
<p>이외에 쿠버네티스의 장점이라고 불리는 기능들이 너무나도 많다.
아래 링크로 들어가보면 기능들에 대해서 상세하게 나와있다.
<a href="https://kubernetes.io/ko/docs/concepts/">https://kubernetes.io/ko/docs/concepts/</a></p>
</blockquote>